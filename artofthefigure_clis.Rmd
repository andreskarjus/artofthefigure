---
title: "The aRt of the figure: data visualisation using R"
subtitle: "PPLS Writing Centre summer workshops"
author: Andres Karjus
output: 
  html_document: 
    toc: yes
---

Welcome to the aRt of the figure workshop for CLiS, _Data visualization with R for corpus linguists_.


# Troubleshooting
This section contains some basic FAQ and tips. It's here at the top so that if you get stuck or confused, you can easily find it.

- Help files. You can always check the parameters of a function by executing `help(functionname)` or `?functionname` or searching for the function by name in the Help tab on the right. Function arguments have names, but names can be omitted if using them in their intended order; they can be looked up in the help files.
- See the line of text between this window and the console, besides a little yellow square icon? Click this to see the table of contents and jump between sections quickly. You can also use CTRL+F (CMD+F) to search.

## There's a red badge with a white X on the left sidebar, what's that?
- That's signalling a syntax error on that line; executing that line would also produce an error. Try to fix it if one pops up. Note that the yellow triangles signal warnings - this line will run, but something might be wrong with it. Note that magrittr's placeholders (.) generate warnings, but they can be ignored.

## What were the shortcuts for running code?
- CTRL+ENTER (PC) or CMD+ENTER (Mac) runs a line and puts the cursor on the next line. ALT+ENTER runs the line but does not advance the cursor.
- To run a line, the cursor has to be on the line, but it does not have to be in the beginning of the end.
- You can always copy-paste or write commands to the console and run them separately from a larger code block (or drag-select a command and press ALT+ENTER).
- You can always use the UP arrow key to go back to previous commands in the console.

## Plots appear in the script window instead of the Plots panel on the right, help!
Tools -> Global Options -> R Markdown -> untick "Show plots inline..."

## My plotting panel suddently looks weird or axes are hidden
Run the `dev.off()` command to reset the plotting device (and parameters).

## Error in somefunction(someparameters) : could not find function "somefunction"
This indicates the package is not loaded. Use the relevant `library()` command to load the package that includes the missing function. There are `library("package")` calls in the beginning of each section that requires them. You really need to load a package once per session, but they are there anyway to keep the script modular for easier revisiting. In general, it's better practice to have library() calls in the head of the script file.

## Error in library("...") : there is no package called '...'
Either the package is not installed, or you misspelled its name. You should have installed the necessary packages before the start of the workshop. If you did not (indicating by `library()` giving you a "package not found" error), then here are the relevant installation commands.
```{r, echo=F, eval=F}
# Do NOT run these unless you are missing the packages! Also if you do, run ONLY the one you need, not all (which might take a while depending on internet speed).
install.packages("magrittr")    # pipes for R
install.packages("ggplot")      # an alternative plotting device for R
install.packages("cowplot")     # ggplot addon
install.packages("ggbeeswarm")  # ggplot addon
install.packages("reshape2")    # data wrangler for ggplot
install.packages("RColorBrewer")# nice color palettes  
install.packages("viridis")     # nice color palettes  
install.packages("plotly")      # for the interactive plots; plot_ly, plot_geo
install.packages("datasauRus")  # a dataset
install.packages("languageR")   # to get the "english" reaction time data
install.packages("igraph")      # constructing and plotting networks
install.packages("visNetwork")  # plotting interactive networks
install.packages("wordcloud")   # exactly what it says
install.packages("quanteda")    # corpus management and text analysis
install.packages("text2vec")    # a corpus & NLP package; also comes with a dataset
install.packages("raster")      # geographical maps
install.packages("corrplot")    # small package that does nice correlation plots
install.packages("rmarkdown")   # for rendering R Markdown documents
# Note that these in turn have dependencies, ~50 packages in total amongst them, which will also be installed.
```

---


# A little refresher

This section just recaps the preparatory exercise.
```{r, echo=T, eval=F}
# This is a code block, distinguishable by the gray shaded background.
# This is a line of code:
print( "Hello! Put your text cursor on this line (click on the line). Anywhere on the line. Now press CTRL+ENTER (PC) or CMD+ENTER (Mac). Just do it." )

# The command above, when executed (what you just did), printed the text in the console below. Also, this here is a comment. Commented parts of the script (anything after a # ) are not executed. This R Markdown file has both code blocks (gray background) and regular text (white background).
```

(Also, if you've been scrolling left and right in the script window to read the code, turn on text wrapping ASAP: on the menu bar above, go to Tools -> Global Options -> Code (tab on the left) -> tick "Soft-wrap R source files")

So, `print()` is a function. Most functions look something like this: 

- `myfunction(inputs, parameters)`

All the inputs to the function go inside the ( ) brackets, separated by commas. In the above case, the text is the input to the `print()` function. All text, or "strings", must be within quotes. Note that commands may be nested; in this case, the innermost are evaluated first:

- `function2( function1(do, something),   parameters_for_function1 )`
- function1 is evaluated first, and its output becomes the input for function2

Don't worry if that's all a bit confusing for now. Let's try another function, `sum()`:

```{r basicmath, eval=F}

sum(1,10) # cursor on the line, press CTRL+ENTER (or CMD+ENTER on Mac)
# You should see the output (sum of 1 and 10) in the console. 
# Important: you can always get help for a function and check its input parameters by executing 
help(sum)  # put the name of any function in the brackets
# ...or by searching for the function by name in the Help tab on the right.

# Exercise. You can also write commands directly in the console, and executing them with ENTER. Try some more simple maths - math in R can also be written using regular math symbols (which are really also functions). Write 2*3+1 in the console below, and press ENTER.

# Let's plot something. The command for plotting is, surprisingly, plot().
# It (often) automatically adopts to data type (you'll see how soon enough).
plot(42, main = "The greatest plot in the world") # execute the command; a plot should appear on the right.
# OK, that was not very exciting. But notice that a function can have multiple inputs, or arguments. In this case, the first argument is the data (a vector of length one), and the second is 'main', which specifies the main title of the plot. 
# You can make to plot bigger by pressing the 'Zoom' button above the plot panel on the right.

# Let's create some data to play with. We'll use the sample() command, which creates random numbers from a predifined sample. Basically it's like rolling a dice some n times, and recording the results.
sample(x = 1:6, size = 50, replace = T) # execute this; its output is 50 numbers 

# If an output is not assigned to some object, it usually just gets printed in the console. It would be easier to work with data, if we saved it in an object. For this, we need to learn assignement, which in R works using the equals = symbol (or the <-, but let's stick with = for simplicity).
dice = sample(x = 1:6, size = 50, replace = T)  # what it means: xdata is the name of a (new) object, the equals sign (=) signifies assignement, with the object on the left and the data on the right. In this case, the data is the output of the sample() function. Instead of printing in the console, the output is assigned to the object.
dice # execute to inspect: calling an object usually prints its contents into the console below.
# Let's plot:
hist(dice, breaks=20, main="Frequency of dice values") # plots a histogram (distribution of values)
plot(dice)               # plots data as it is ordered in the object
xmean = mean(dice)       # calculate the mean of the 50 dice throws
abline(h = xmean, lwd=3) # plot the mean as a horizontal line

# Exercise: compare this plot with your neighbor. Do they look the same? Why/why not?

# Exercise: use the sample() function to simulate 25 throws of an 8-sided DnD dice.

```

The next sections will go over basic data types and suitable plots. If we have time, we'll also learn how to make app-like interactive plots.



# Numerical data

Numerical values include things we can measure on a continuous scale (height, weight, reaction time), things that can be ordered ("rate this on a scale of 1-5"), and things that have been counted (number of participants in an experiment, number of words in a text).

## A single continuous variable

We will be using the English visual lexical decision and naming reaction time dataset from the `languageR` package. 
```{r boxplots_hist}
# To make things easier in the beginning, we'll subset the (rather large) dataset; just run the following line - we'll see how indexing and subsampling works later;
library(languageR) # load the necessary package
eng = english[ c(1:100, 2001:2100),  c(1:5,7)]

# We can inspect the data using convenient R commands.
dim(eng)      # dimensions of the data.frame
summary(eng)  # produces an automatic summary of the columns
head(eng)     # prints the first rows
# In RStudio, you can also have a look at the dataframe by clicking on the little "table" icon next to it in the Environment section (top right).
help(english)     # built in datasets often have help files attached

# Plotting time! Let's explore for example the "familiarity" score distribution
eng$Familiarity         # the $ is used for accessing (named) column of a dataframe (or elements in a list)
eng[, "Familiarity"]    # this is the other indexing notation: [row, column]
plot(eng$Familiarity )  # the x-axis is just the index, the order the values are in the dataframe
hist(eng$Familiarity, breaks=10) # a histogram shows the distribution of values ('breaks' change resolution)
boxplot(eng$Familiarity)         # a boxplot is like a visual summary()
stripchart(eng$Familiarity, vertical=T, add=T, col=rgb(0,0,0,0.4), pch=16)   # points could be added with points() or stripchart(add=T)

```

Exercises: let's practise modifying function parameters by fiddling a bit with this plot (and let's see if we can improve the rather basic default look). Make a new code block here for the exercises (click the green `insert` on the toolbar above), and copy the boxplot and stripchart lines from above.

- Have a quick chat with your neighbor about the interpretation of the plot, and how it relates to summary statistics.
- The points added by stripchart() are overlapping and not very informative. Add the method parameter, and specify it's value as "jitter", which randomly distributes the points along the x-axis. Since we're "adding" stripchart on top of boxplot, run the boxplot command first (again).
- The default color of the points is black. Change it to something else by adding the parameter col to the points command (remember, parameters are separated by commas, and they are given values using the = sign; color names must be in quotes, e.g., "darkred"). Try setting a transparent color using the rgb() command, e.g. try col=rgb(0,0,0,0.4)
- The default point shape is here is pretty ugly. Change it using the pch parameter, setting it to e.g. 16 (which stands for filled circles; see ?points for the full list)
- You will have noticed that the boxplot has an outlier point on top, but the same is duplicated by the added jittered points. Remove the boxplot outlier by setting outline=F for boxplot().
- Add a title and y-axis label to the boxplot using main and ylab
- Figure out a way to mark the mean on the plot, to complement the median line.
- A bit more advanced: make this a nice pedagogical example, use the `text()` function to add the labels `summary()` would give you, to the plot, for example, make it say "median" next to the boxplot, where the median line is (i.e., with coordinates x=1.3 and y=3.455). This could be achieved with either a single `text()` call, or with multiple individual ones, one for each statistic. Preferably do this programmatically, rather than copy-pasting values from summary() by hand.
- A bit more advanced: add the actual words to the plot, next to the box, using `text()`. Note that there's quite a few words, so they're likely to obscure each other - change text size using the `cex` parameter, or better yet, only add a subset of the words, either using `sample()`, or a sequence of indices (e.g. `seq(1,100,3)`).

```{r grouped_boxplot, echo=T, eval=T}
# Another way to plot boxplots, grouping them by some relevant variable:
boxplot(eng$RTnaming ~ eng$AgeSubject, main="Reaction time by age") # note the ~ notation
grid() # why not add a grid for reference

# A slightly nicer version:
boxplot(eng$RTnaming ~ eng$AgeSubject, main="Reaction time by age", ylab="Reaction time", 
        border=c("brown", "forestgreen"), boxwex=0.7, cex=0.4) 
abline(h=seq(6,7,0.1), col=rgb(0,0,0,0.1))  # adds vertical lines instead of full grid
```



## A note on colors

The `rgb(red, green, blue, alpha)` function allows making custom colors; `alpha` controls transparency. Possible values range between 0 and 1 by default. Below is a piece of code that generates an example of how the color scheme works (don't worry if you don't understand the actual code, this is above the level of this workshop; just put the cursor in the code block and press CTRL+SHIFT+ENTER (CMD+SHIFT+ENTER on Mac).

```{r colormagic, echo=F}
# An example of how RGB color mixing works.
{
  xpar=par(no.readonly = T)
  par(bg="black", mar=c(0,0,1,0), mfrow=c(2,1))
  plot(NA, ylim=c(-0.1,1.1), xlim=c(-0.1,1.1), type="n", xaxt="n", yaxt="n", main="")
  mtext("red vs blue, green=0", col="white")
  g=0
  for(r in seq(0,1,0.2) ){
    for(b in seq(0,1,0.2)){
      points(r, b, col=rgb(red=r,green=g,blue=b, alpha=1), pch=16, cex=6, lwd=1)
      text(r, b, paste0("rgb(",paste( c(r,g,b), collapse=","), ")"),
           cex=0.7, col="white", family="mono", font=2)
    } 
  }
  plot(NA, ylim=c(-0.1,1.1), xlim=c(-0.1,1.1), type="n", xaxt="n", yaxt="n", main="")
  mtext("red vs blue, green=0.5", col="white")
  g=0.5
  for(r in seq(0,1,0.2) ){
    for(b in seq(0,1,0.2)){
      points(r, b, col=rgb(red=r,green=g,blue=b, alpha=1), pch=16, cex=6, lwd=1)
      text(r, b, paste0("rgb(",paste( c(r,g,b), collapse=","), ")"),
           cex=0.7, col="white", family="mono", font=2)
    } 
  }
  par(xpar)
}
```

Another good way to use colors is to use ready-made palettes.


## Inspecting two numeric variables

```{r scatterplots}
library(RColorBrewer) # load a color palette package
library(viridis)      # another color package, might need later

plot(eng$WrittenFrequency, eng$Familiarity) 

# Why not color-code by age. Note that plot() also accepts the ~ formula notation, so we can also just specify the column names when we set the data parameter.
cols= brewer.pal(3, name = "Set2")
plot(WrittenFrequency ~ Familiarity,  data=eng,
     col=cols[AgeSubject], pch=20)


# Exercise. This is mostly to get a feel for objects, indexing, and functions. Copy the plot code from above. Make this nicer by adding a legend and a grid, and make this legible to the colour-blind, (and printable in black-and-white) by specifying point shape per group the same way color was specified above. Here are the relevant bits:

pnts = c(1,0)  # vector of point shape values, similar to the vector of color values; index by AgeSubject

# plot() code somewhere here, with pch specified analogously to col above

# set cex=0.8 within plot()
# add a grid(), set col=rgb(0,0,0,0.3) and lty=3
# add a legend:
legend("topleft", pch=pnts, legend = levels(eng$AgeSubject), col=cols, cex=0.7, bty="n") 
# hmm... now "old" is green, maybe make "young" green instead by reversing the colors:
cols = brewer.pal(3, name = "Set2")[c(2,1)] # and run the plot again

```

```{r regression, eval=F, echo=F}
## Bonus: plotting regression lines
# This workshop is not focused on actual statistical techniques (maybe another time!), but in case you ever need to plot a regression line* - this is pretty simple in R:

plot(WrittenFrequency ~ Familiarity,  data=eng, col="black", pch=20)
grid(col=rgb(0,0,0,0.2), lty=1)

# do the regression analysis:
# use the same formula notation as above, and the same data parameter, as the input for lm()
# use the lm(...) as an input to abline()
# abline can handle the output of the lm (linear model) command, extracting the intercept and beta coefficient
# could also adjust the look of abline a bit with: col=rgb(0,0,0,0.3), lwd=4

# *Of course we already recognized that the data is more complex as initially thought (consisting of distinct groups), so a proper regression model should take that into account.
```



## Time series

While a whole subject on its own, we will have a quick look at plotting time series - data reflecting changes in some variable over time.
```{r timeseries, eval=T, echo=T}
library(quanteda, quietly = T)  # load a corpus management package; we'll also make use of a dataset in it

# let's inspect the data first:
length(data_corpus_inaugural$documents$texts)
rownames(data_corpus_inaugural$documents)
head(tokens(data_corpus_inaugural$documents$texts[[1]])[[1]],30) 

# Exercise. Use summary() on data_corpus_inaugural$documents. Then have a look at speech number 58, and find out who's giving the speech (hint: presidents are recorded in the same dataframe)


# The following line of code will tokenize the US Presidents' inaugural speeches corpus and count the words
nw = ntoken( tokens(data_corpus_inaugural$documents$texts) )
plot(nw, xlab="", ylab="speech length")

# Exercise: make the plot easier to read by changing line type (lty) to "l" or "b" or "o". Remove the default axis (xaxt="n") and add a custom axis:
axis(side = 1, at = 1:58, labels = data_corpus_inaugural$documents$Year, las=1, line=-0.4, col=NA, col.ticks = "black")
# Adjust label size using the cex.axis parameter. Note that since axes are "added on", you'll need to run the plot(...) again.
# Rotate axis tick labels by setting las to 2
# Copy the line with the axis() code to add a second axis to side=3 (top) that uses data_corpus_inaugural$documents$President as labels



# The following lines of code will extract & count mentions of the target words in the US Presidents' inaugural speeches corpus
tok = tokens_tolower(tokens(data_corpus_inaugural$documents$texts)) # tokenized corpus
target1="^(he|him|m[ea]n|boys*|male|mr|sirs*|gentlem[ae]n)$"
target2="^(she|her|wom[ea]n|girls*|female|mrs|miss|lad[yies]*)$"
line1 = sapply(tok, function(x) length(grep(target1, x))/length(x)*1000 )
line2 = sapply(tok, function(x) length(grep(target2, x))/length(x)*1000 )

plot(NA, ylim=c(0,15), xlim=c(1,58), ylab="mentions per 1000 words", xlab="year", xaxt="n"); grid()
axis(side = 1, at = 1:58, labels = data_corpus_inaugural$documents$Year,las=2, cex.axis=0.6)
lines(line1, type="o", pch=20) # mentions of he/his/man... etc
lines(line2, type="o", pch=20) # mentions of she/her/woman... etc

# Exercise: but oh no, the lines are the same color so there's surely no way of guessing which line represents women and which one men. Add color and/or point shapes to the lines(); you could either define your own colors, or use brewer.pal()

# Exercise: define your own regex (or just a word, if you don't know regex) and visualize some more comparisons. Adjust the ylim() parameter if the lines don't fit.

# Exercise: if you have time, might as well explore the corpus a bit; use the kwic() function:
kwic(data_corpus_inaugural, "wom[ae]n", valuetype = "regex", window = 3)
# adjust the window parameter, or adjust your actual RStudio window/pane size, if the kwic's are not lined up nicely

```


# Categorical data

Categorical/nominal/discrete values cannot be put on a continuous scale or ordered, and include things like binary values (student vs non-student) and all sorts of labels (noun, verb, adjective). Words in a text could be viewed as categorical data.

## Categories and contingency tables


```{r categorical}
library(RColorBrewer)
library(text2vec) 
# this is a useful package for dealing with large corpora and machine learning/NLP, similar to quateda, but works differently and has some different models in it; we'll only be using a dataset from it though.

# We'll make use of the movie reviews dataset
data("movie_review")
# Use dim() and summary() to quickly get an idea of what's in there

tokens(movie_review[1,3])[[1]][1:20] # parse words, have a quick look


# Exercise: recode the data, figure out how the functions work, discuss the functions and the result with a neighbor:

# recode the sentiment
movie_review$sentiment = ifelse(movie_review$sentiment > 0, yes="pos", no="neg")

# find which reviews explicitly say the word "bad"
says_bad = grepl("bad", movie_review[,3], ignore.case = T)
movie_review$sayswhat = ifelse(says_bad, yes="says_bad", no="doesntsay")

# cross-tabulate the two columns
sent = table(movie_review[, c("sayswhat", "sentiment")])
# have a look at the object first

# plot using mosaicplot
mosaicplot(sent, col=brewer.pal(3, "Dark2")[c(2,1)] ) # what's the interpretation?

```

```{r heatmaps, eval=F, echo=F}
library(viridis)
## Bonus: heatmaps
# Mosaicplots and heatmaps are related concepts, but heatmaps use color rather than size to convey values
# Inter-speech distances as operationalized by their (weighted) word usage distributions
distmat=as.matrix(textstat_dist(dfm_tfidf(dfm(corpus_subset(data_corpus_inaugural), tolower = T, stem=T, remove=stopwords("english"), remove_punct=T))) )

heatmap(distmat , symm=T, Rowv=NA, Colv=NA, col=viridis(100, direction = -1) ) # a heatmap of that, lighter indicates more similarity

# A heatmap (of sorts) of number of periods per president:
heatmap(table(data_corpus_inaugural$documents$President,
              data_corpus_inaugural$documents$Year)[data_corpus_inaugural$documents$President,],
        Rowv=NA, Colv=NA, col=gray.colors(5, start = 1,end=0))
```

```{r corrpolot, eval=F}
## Bonus 2:
# Large correlation matrices (= a matrix of correlation values between a bunch of variables; usually via the cor() function) are hard to grasp, but visualization helps; there's a little package that does just that: the corrplot package. It is similar to heatmaps, but generates plots with correlation matrices in mind. The package needs to be installed first of course.
library(corrplot)
corrplot(cor(eng[,c(1:3,6)]) )
```


## Intermission: pipes

```{r}
library(magrittr)

# This would be a good point to introduce magrittr's pipe %>% command. It's super useful! The shortcut in RStudio is CTRL-SHIFT-M (or CMD-SHIFT-M). If you're familiar with Bash pipes: it's the same thing. If you're interested in the somewhat curious name: https://en.wikipedia.org/wiki/The_Treachery_of_Images

# Exercise. Try it out and discuss the results with your neighbor.
1:3
sum(1:3)
x=1:3
sum(x)
1:3 %>% sum()  # same result, and not much difference in spelling it out either
1:3 %>% sum() %>% rep(times=4)  # what does that do?
# "." can be used as a placeholder if the input is not the first argument, so the above could also be spelled out as:
1:3 %>% sum(.) %>% rep(., times=4)  # or
1:3 %>% sum(.) %>% rep(., 4)        # and it's the same as
rep(sum(1:3), times=4)

# another example:
c(1,1,1,2) %>% match(x=2, table=.)  # 

# something longer (take it apart to see how it works):
"hello" %>% gsub(pattern="h", replacement="H", x=.) %>% paste(., "world")

```


## Words!

```{r wordclouds}
library(wordcloud) 
library(magrittr)
library(quanteda)

# Let's create an object with a bunch of text:
sometext = "In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort. It had a perfectly round door like a porthole, painted green, with a shiny yellow brass knob in the exact middle. The door opened on to a tube-shaped hall like a tunnel: a very comfortable tunnel without smoke, with panelled walls, and floors tiled and carpeted, provided with polished chairs, and lots and lots of pegs for hats and coats—the hobbit was fond of visitors. The tunnel wound on and on, going fairly but not quite straight into the side of the hill — The Hill, as all the people for many miles round called it — and many little round doors opened out of it, first on one side and then on another. No going upstairs for the hobbit: bedrooms, bathrooms, cellars, pantries (lots of these), wardrobes (he had whole rooms devoted to clothes), kitchens, dining-rooms, all were on the same floor, and indeed on the same passage. The best rooms were all on the left-hand side (going in), for these were the only ones to have windows, deep-set round windows looking over his garden, and meadows beyond, sloping down to the river."


# Now let's do some very basic preprocessing to be able to work with the words in the text:
words = gsub("[[:punct:]]", "", sometext) %>%  # remove punctuation 
  tolower() %>%                                # make everything lowecase
  strsplit(., split=" ") %>% unlist()  # tokenize; the unlist is due to strsplit's default list output
# Inspect the object we just created. It should be a vector of 236 words.

# Quick magrittr exercise: rewrite the following lines as a single line with %>% 
x = grep("hobbit", words)
n = length(x)
txt = paste("Hobbits are mentioned", n, "times.")
print(txt, quote=F)


# Some ways to inspect and visualize textual data
sortedwords = table(words) %>% sort()    # counts the words and sorts them
# Exercise: have a look at the data using the head() and tail() commands

plot(sortedwords, xaxt="n")
axis(1, 1:length(sortedwords), names(sortedwords), las=2, cex.axis=0.5) # add the words


# Time to use the wordcloud package we loaded earlier.
# If you get an error saying 'could not find function "wordcloud"', then you need to load the package (with the library command above).
par(mar=c(0,0,0,0)) # set plot area parameters to remove margins

wordcloud(words = names(sortedwords), freq=as.numeric(sortedwords), min.freq = 0)

# Note: if R gives you errors (saying word x could not fit), ignore them. Also, run dev.off() after playing with wordclouds to reset graphics.

# Ideally we would remove stopwords (the, and...) before plotting things like wordclouds. There are packages  (tm, text2vec, quanteda) that do that in various ways - or you could write some code to do it yourself (using clever math to give greater weight to "context" words, removing stopwords using lists or regular expressions, etc).
# A very simple trick is to just remove all short words:
sortedwords2 = 
  names(sortedwords) %>% 
  nchar() %>%  
  {.>3} %>% 
  sortedwords[.] 
# look up the help files of the commands used here if you'd like to understand how this works exactly

wordcloud(names(sortedwords2), as.numeric(sortedwords2), min.freq = 0, col=terrain.colors(10), scale=c(3,0.3))
# set random.order = F to have more frequent words in the middle


# Another way is to use quanteda for all the preprocessing as well as the wordclouds:
parsed = dfm(sometext, 
             remove = stopwords('english'), 
             remove_punct = TRUE, 
             stem = FALSE) 
parsed[,1:10] # quick look at the new data structure
textplot_wordcloud(parsed, min_count = 1, color=terrain.colors(100)) 
# this actually just uses wordcloud() internally
# Exercise: try setting stemming to TRUE and see how that changes the picture 

# once you are done with this part, execute this to clear the plotting area parameters:
dev.off()
```


# ggplot2

We have now seen how to visualize the most common types of data using R's basic plotting tools, and picked up some basic R skills on the way. Before diving into various other things like networks and maps, we'll have a look at an alternative plotting package, `ggplot2`. It uses a different approach to plotting, and a slightly different syntax (just to confuse you a bit more). It also comes with default colors and aesthetics which many people find nicer than those of the base `plot()`. A particularly useful feature of `ggplot2` is its extendability (or rather the fact people are eager to extend it), with an ever-growing list of addon-packages on CRAN with an extended selection of themes and more niche visualizations.

## Scatterplot of two numeric variables
```{r ggplot_scatterplots}
library(ggplot2)    # load ggplot2

# We're using the same english dataset subset (eng) as in the first section.
ggplot(eng, aes(x=WrittenFrequency, y=Familiarity, col=AgeSubject,shape=AgeSubject)) + 
  geom_point()
# the data are defined in the ggplot command, aes() specifies variables and grouping variables
# Exercises:
# the + adds layers, themes and other options
# try adding scale_colour_brewer(palette = "Dark2") 
# try adding a theme like theme_minimal() - start typing theme_ and see what RStudio's autocomplete offers
# remove or move the legend using theme(), specifying the legend.position parameter with value "none", "top", etc.

```

Exercise: explore the relationship between `WrittenFrequency` and `RTnaming` (reaction time), using `AgeSubject` as the coloring variable; use `geom_smooth(method="lm")` to add regression lines (analogous to `abline(lm()))` from earlier.

A note on `geom_smooth()` - this function attempts to fit a model to the data, bu default either a Loess or GAM curve. While this is a convenient function in itself, it should be used only if one understands how these regression methods work and what their interpretation is - particularly that of Loess, which is often misused.

## Translating previous visualizations to ggplot2

```{r ggplot_timeseries}
# Time series
series=data.frame(y=sort(runif(100))+runif(100,-0.1,0.1))
ggplot(data = series, aes(x = 1:100, y = y)) +
  geom_line(color = "turquoise", size = 2) +
  theme_minimal() +
  NULL
# try adding x and y axis labels and title using e.g. labs(x = "time") or xlab(), and ggtitle()
# a nice trick is to add NULL in the end of the ggplot call (on a new line) - this way, in case you remove or comment out the last option (e.g, the theme_minimal in this example), you don't need to delete the + on the last line (since NULL does nothing).
```


```{r ggplot_heatmap}
# Heatmaps revisited / alliteration visualized
library(reshape2) # needed to wrangle data into a ggplot2-friendly format
library(ggplot2)

# This block of code will parse a stanza and organize data in a suitable format for the ggplot example below.
{
  w=tokens(tolower("Then were not summer's distillation left - A liquid prisoner pent in walls of glass - Beauty's effect with beauty were bereft - Nor it nor no remembrance what it was. -"))[[1]]
  d= w %>% strsplit(split="") %>% as.tokens() %>% dfm() %>% as.matrix() %>% melt()
  d$docs = as.numeric(gsub("text", "", d$docs))
  d$features = d$features %>% factor(.,levels(.)[order(levels(.))]) 
  # possibly not the most elegant solution
}

# plot the heatmap:
ggplot(data=d, aes(y=docs, x=features, fill=value)) + 
  geom_tile(colour = "lightgray") + ylab("> > >") + xlab("") +  
  theme_classic() + scale_fill_gradient(low = "white", high = "steelblue") + 
  scale_y_continuous(breaks = 1:length(unique(d$docs)), labels=w)

```



## Distributions, boxplots, histograms and more

We'll keep using ggplot, but do something different for a change, looking at different ways of visualizing distributions, and how visualization choices can lead to different and sometimes unintended interpretations.

```{r ggplot_distributions}
library(cowplot)    # provides plot_grid()
library(ggbeeswarm) # an additional geom

set.seed(1); x2=round(rnorm(400,35,10))+30; x1=round(rnorm(1000,35,10)) # nevermind the random data creation for now, just run this line, and then focus on the plotting code below:

# Poll: how likely is it that these are samples from the same distribution/population, or are on average similar?
plot_grid(
  ggplot() + aes(x1) + geom_bar(width=1) + theme_gray(base_size=8),
  ggplot() + aes(x2) + geom_bar(width=1) + theme_gray(base_size=8) 
)

options(scipen=999)
ks.test(x1,x2)
# Step 2: lims(x, y)


# Visualizing distributions with different methods. 
set.seed(5);x=c(runif(50,1,160), rnorm(100,60,10), rnorm(100,100,10)) # some more random data, just run it
# Question: is this variable ~normally distributed? (same data, just two different views)
cowplot::plot_grid(
  ggplot() + aes(x) + geom_histogram(binwidth = 23),
  ggplot() + aes(x) +  geom_density(adjust = 2) + geom_rug(color=rgb(0,0,0,0.2))
)
# Step 2: binwidth, adjust

# Here's another look at the same data:
cowplot::plot_grid(align = "h",
  ggplot() + geom_boxplot(aes(x=0,y=x),width=0.7) + xlim(-1,1),
  ggplot() + aes(0,(x))+ geom_bar(stat = "summary", fun.y = "mean") + stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge", width=0.2) +  coord_cartesian(c(-1,1), c(1,150)),
  ggplot() +  aes(0,x) + geom_violin(adjust=1) +  geom_point(shape=95, size=3, color=rgb(0,0,0,0.2)),
  ggplot() +  geom_beeswarm(aes(0,x))
)


# About axes. Which of these three variables (y1, y2, y3) is experiencing the most drastic change over time?
set.seed(1); y=sort(runif(10,3,4))*runif(10, 0.8,1.2) 
cowplot::plot_grid(ncol=3,
  ggplot() + aes(x=1:10, y=y ) + geom_line(col="red") + ylab("y1") ,
  ggplot() + aes(x=1:10, y=y ) + geom_line(col="orange") +ylim(0,5) + ylab("y2"),
  ggplot() + aes(x=1:10, y=y ) + geom_line(col="darkblue") +ylim(0,20) + ylab("y3") 
)

```

By the way, the `plotly` package we'll use below gets along with `ggplot2` very nicely, and you can convert plots created using the latter into interactive ones using the `ggplotly` function. There is also the `gganimate` package which can be used to create animated plots in the form of GIFs. plotly can do animations as well, but interactive, which we'll see later.



# Graphs, networks, and some more corpus linguistics

## Social networks

The following example will look into plotting social networks of who knows who.
```{r igraph_networks, eval=T, echo=T}
library(igraph, warn.conflicts = F)  # load the package; this needs to be done once after starting R/RStudio

# Create an object with some random Scottish people (this could be a sample from a sociolinguistic study or whatever)
scots=c("Angus","Archibald","Baldwin","Boyd","Cinead","Craig","Diarmid","Donald","Duncan","Eachann","Erskine","Ethan","Fergus","Fingal","Fraser","Hamilton","Iain","Irvine","James","Muir","Mungo","Owen","Raibert", "Lyall", "Margaret", "Mairi", "Morag", "Murdina","Rhona", "Sorcha", "Thomasina","Una") 
nscots = length(scots) # record the number of people in an object
# call the nscots object to see how many there are

mates = matrix(sample(0:1,nscots^2,T,prob=c(0.95,0.05)), ncol=nscots, nrow=nscots, dimnames=list(scots, scots)); diag(mates)=0 # this creates a randomized matrix signifying friendships; no need to think about this too hard for now
mates[1:10,1:10] # but have a look at it anyway; '1' means these two people know each other; this line prints the first 10 rows and 10 columns
scotgraph = graph_from_adjacency_matrix(mates, mode = "undirected", diag=FALSE) # creates a graph object; igraph needs to be loaded

# Have a look at the scotgraph object (list of links/"edges"). 
# The raw data in the graph object is not particularly useful. Plotting the graph will help though. 
# Exercise: call plot on the scotgraph object.

#

# This action produced a network... but the defaults are not very nice looking.
# Let's modify the plotting parameters, and add color coding.
mf = c(rep("m", nscots-9), rep("f", 9)) # create a vector of labels (there happens to be 9 women in the dataset)
mfcolors = ifelse(mf=="m", yes="navy",no="tomato")
par(mar=c(0,0,0,0)) # makes plot margins more suitable for igraph plotting
plot(scotgraph, 
     vertex.size=4, vertex.color="lightgray", vertex.frame.color=NA,   # vertex color and size
     vertex.label.cex=0.9, vertex.label.dist=0.1, vertex.label.font=2, # vertex labels
     vertex.label.color=mfcolors,   # label color
     edge.color=rgb(0,0,0,0.3))


# Bonus: some graph statistics
ecount(scotgraph) # how many links in the network
sort(degree(scotgraph), decreasing = T)[1:3] # top most popular people (vertex degree, i.e. how many edges/links a vertex/node has)
distances(scotgraph, v = "Mungo", to = "Duncan") # how distant are those dudes in the network (least n edges)
mean_distance(scotgraph, unconnected = T) # average distance between the vertices (people)

```

Let's try something else. Using the same graph data, we'll recreate it using another package, visNetwork, which makes graphs interactable (note that there are also other network packages, such as networkD3 and ggraph for ggplot2).
```{r visnetwork}
library(visNetwork, warn.conflicts=F)

scotgraph_v = toVisNetworkData(scotgraph) # converts the previous igraph object into a visNetwork object
# adjust some parameters; note how the visnetwork object is really just a list with 2 dataframes.
head(scotgraph_v$nodes)
scotgraph_v$nodes$size = 10
scotgraph_v$edges$color = rgb(0,0,0,0.3)
# plot it:
visNetwork(nodes = scotgraph_v$nodes, edges = scotgraph_v$edges)
#Try clicking on the nodes, moving them, and zooming. Pretty neat, no? You can also modify the physics engine to adjust the gravitational pull between the nodes, or disable it.
```

## Citation networks

In the following examples, we'll use the inaugural speeches of US presidents again. We'll start by looking into which presidents mention or address other presidents in their speeches. We'll extract the mentions programmatically rather than hand-coding them.
```{r presidential_mentions_network}
library(quanteda) # make sure this is loaded
library(igraph, warn.conflicts=F)
library(visNetwork, warn.conflicts=F)

speeches = gsub("Washington DC", "DC", data_corpus_inaugural$documents$texts) # replace city name to avoid confusion with the president Washington (hopefully)
speechgivers = data_corpus_inaugural$documents$President # names of presidents giving the speech
presidents = unique(data_corpus_inaugural$documents$President) # presidents (some were elected more than once)


# The following piece of code looks for names of presidents in the speeches using grep(). Just run this little block:
{
  mentions = matrix(0, ncol=length(presidents), nrow=length(presidents), 
                    dimnames=list(presidents, presidents))
  for(president in presidents){
    foundmentions = grep(president, speeches)
    mentions[speechgivers[foundmentions], president ] = 1
  }
}
# Note: this is not perfect - the code above concatenates mentions of multiple speeches by the same re-elected president, "Bush" as well as "Roosevelt" refer to multiple people, and other presidents might share names with other people as well. You can check the context of keywords using quanteda's kwic() command:
kwic(data_corpus_inaugural, "Monroe")
#

# Have a look at the data
mentions[30:35, 30:35] # rows: one mentioning; columns: being mentioned
counts = data.frame(names=colnames(mentions), count=apply(mentions, 2, sum))

ggplot(counts) + 
  geom_col(aes(y=count, x=names), fill= brewer.pal(3,"Set2")[1]) + 
  coord_flip() + 
  scale_x_discrete(limits = counts$names) +
  theme_dark()


pgraph = graph_from_adjacency_matrix(mentions, mode="directed") # this uses igraph again
# you can have a look at the basic igraph plot if you want

# this uses visNetwork:
v = toVisNetworkData(pgraph)
visNetwork(nodes = v$nodes, edges = v$edges) 
# check how it looks before we add all the fancy stuff

# Exercise: now use pipe %>% notation and the following functions to adjust the visNetwork plot (i.e., visNetwork(..) %>% visNodes(..) etc). See how the graph changes after each addition. Feel free to play around with the parameters!
# visNodes(size = 10,  shadow=T, font=list(size = 30))
# visIgraphLayout("layout_in_circle", smooth=T)  # steal a better layout from igraph
# visEdges(arrows = "to",  shadow=T, smooth=list(type="discrete"), selectionWidth=5)
# visOptions(highlightNearest = list(enabled = T, hover = T, degree=1, labelOnly=F, algorithm="hierarchical"), nodesIdSelection = T) # interactive selection options

# Finally, click "Export" under the Viewer tab, and select "Save as webpage".

```

## What else is in there?

While we're at it, let's try to probe into the contents of the speeches and use some more interactive plotting tools to visualize it.
```{r plotly, eval=T, echo=T}
library(quanteda, warn.conflicts=F) # this needs to be loaded
library(plotly, warn.conflicts=F)   # this is new

# This block of code will extract the top terms (after removing stopwords) from the speeches, calculate the distance between the speeches based on word usage, and compress it all into 2 dimensions.
termmat = dfm(data_corpus_inaugural, tolower = T, stem=F, remove=stopwords("english"), remove_punct=T)
topterms = lapply(topfeatures(termmat, n=10, groups=rownames(termmat)), names)
distmat = 1-textstat_simil(termmat, method="cosine") # calculate distances
mds = as.data.frame(cmdscale(distmat,k = 2)) # multidimentsional scaling (reduces distance matrix to 2 dimensions)
# have a look at the object using head()

mds$tags = paste(names(topterms), sapply(topterms, paste, collapse="<br>"), sep="<br>") # add top word labels to the data


# Exercise. The following makes use of the plotly package. Create your first plotly plot out of the following components
a = list(x=mds[55:58,1], y=mds[55:58,2], text=rownames(mds)[55:58],  ax = -20, ay = 30, showarrow = T, arrowhead = 0)  # this is a list with named elements that will be used to add some custom annotations

plot_ly(data = mds, x=~V1, y=~V2, type="scatter", mode = 'markers', hoverinfo = 'text', text = ~tags) # this is the main plotly function - note the somewhat different usage of ~ here to specify variable names

# add the following parameters to the function call above to color speeches by time: color=~1:nrow(mds), colors = viridis(58, direction = -1)
# add annotations, use %>% layout(annotations = a )  
# pipe this in the end as well, the colorbar is not very useful here: %>% hide_colorbar()



# A look into the usage of some words across centuries
termmat_prop = dfm(data_corpus_inaugural, 
                   tolower = T, stem=F, remove=stopwords("english"), remove_punct=T) %>%
                dfm_weight("prop")          # use normalized frequencies
words = c("america", "states",  "dream", "hope",  "business", "peace", "war", "terror")
newmat = as.matrix(termmat_prop[,words]) %>% round(5)
plot_ly(x=words, y=rownames(termmat_prop), z=newmat, type="heatmap", 
        colors = colorRamp(c("white", "orange", "darkred")), showscale = F)
 

# Exercise (easy). Choose some other words! Also try changing the color palette (the function used here, colorRamp, takes a vector of colors as input and creates a custom palette).
# Add a nice background using %>% layout(margin = list(l=130, b=50), paper_bgcolor=rgb(0.99, 0.98, 0.97))
# Discuss the what you see on the plot with your neighbor.

# Exercise (a bit harder). We could get a better picture of what has been said by the presidents if we expanded our word search with regular expressions (^ stands for the beginning of a string and $ for the end, and . stands for any character, so ^white$ would match "white" but not "whites", and l.rd would match "lord" but also "lard" etc). Define some new search terms; below are some ideas. 
words2 = c("america$", "^nation", "^happ", "immigra", "arm[yi]", "^[0-9,.]*$")
# The bit of code below uses grep() to match column names, so unless word boundaries are defined using ^$, any column name that *contains* the search string is also matched ("nation" would match "international"). For each search term, it will find and sum all matching rows. 
newmat = sapply(words2, function(x) rowSums(termmat_prop[, grep(x, colnames(termmat_prop)) ])) %>% round(5)
# You can check which column names would be matched with:
grep("america", colnames(termmat_prop), value=T)
# Then copy the plotly command from above and substitute the z parameter value with newmat.

```


# Making things interactive

```{r plotly_conversions, eval=F, echo=F}
# plotly can be used to create the same kind of plots as you've done with the base plot() function, except interactive. Let's create an interactive time series plot.

tok = tokens_tolower(tokens(data_corpus_inaugural$documents$texts)) 
target1="^(he|him|m[ea]n|boys*|male|mr|sirs*|gentlem[ae]n)$"
target2="^(she|her|wom[ea]n|girls*|female|mrs|miss|lad[yies]*)$"
line1 = sapply(tok, function(x) length(grep(target1, x))/length(x)*1000 )
line2 = sapply(tok, function(x) length(grep(target2, x))/length(x)*1000 )
newlines = cbind(data_corpus_inaugural$documents, mentions=round(c(line1, line2),3), gender=c(rep("m",58), rep("f",58)), row.names = NULL)

plot_ly(newlines, x=~Year, y=~mentions, type="scatter", mode="lines", split=~gender) %>% 
  layout(yaxis=list(title="mentions per 1000 words"))
# The split parameter defines groups (like color/group in ggplot2). Explore how the interactivity works in the new plot.


# We can also easily convert ggplots into plotly plots:
gp = ggplot(eng, aes(x=WrittenFrequency, y=Familiarity, col=AgeSubject)) + 
  geom_point() + theme_gray()
gp # have a look at what that was
ggplotly(gp) # magic

```

# Plots in 3Deeeeee!

```{r scatter3d_exercise}
# Here's a plot similar to what we've seen before:
plot_ly(data=eng, x=~Familiarity, y=~RTlexdec, type="scatter", mode="markers", color=~AgeSubject)
# Discuss the interpretation of the plot with your neighbor.

```
It might be useful to see how these two variables interact with some third variable of interest though. Exercise: make a copy of the code from above and carry out the following changes, inspecting the plot after every step. 

- Change the type value to "scatter3d", and add the z parameter, and set it's value to WrittenFrequency. Make the hover labels more useful by adding  text=~Word, name="" - the first adds words to the labels, the second removes the useless trace label
- change the data input to english (the whole dataset, instead of the subset we've been using)
- add this to adjust markers to display better in this new bigger plot: marker=list(opacity=0.3, size=3)
- add a fourth variable via color: color=~NumberSimplexSynsets (which quantifies homonyny) 
- change the following parameter to a nicer color scale: colors=brewer.pal(11,"RdBu")) and make the background all dark and cool with %>% layout(paper_bgcolor="black", plot_bgcolor="black").
- Discuss the interpretation of the new plot with your neighbor.


Here's something completely useless, but maybe pretty:
```{r, eval=F}
# remember the RGB color plots from earlier, the ones with the black background?
col3 = data.frame(red=runif(1000),green=runif(1000),blue=runif(1000))
plot_ly(col3, x=~red,y=~green, z=~blue, type="scatter3d",mode="markers", marker=list(opacity=0.9), color=I(apply(col3,1, function(x) rgb(x[1],x[2], x[3])))) %>% layout(paper_bgcolor='black') %>%   config(displayModeBar = F) 

```


# Animation

We'll create a modified subset of the `english` dataset to produce some artificial language change data. The scenario: 10 words, over 100 years, observing the interplay of their homonymy and frequency values.
```{r animation_movement}

{    # just run this to create the semi-artificial dataset
  eng2 = english[order(english$NumberSimplexSynsets*runif(nrow(english),0.9,1.1)), 
                 c("WrittenFrequency", "NumberSimplexSynsets")] %>% .[seq(2001, 4000, 2),]
  eng2$NumberSimplexSynsets = eng2$NumberSimplexSynsets * 
    rep(seq(0.8,1.2,length.out=10),100) *runif(100,0.9,1.1)
  eng2$year = rep(seq(1800,1899,1),each=10)
  eng2$word  = as.factor(rep(1:10, 100))
}
# inspect the dataset first

# Plot the change over time:
plot_ly(eng2, x=~NumberSimplexSynsets, y=~WrittenFrequency, 
        type = 'scatter', mode = 'markers', 
        frame=~year,         # the frame argument activates the animation functionality
        color=~word, colors=brewer.pal(10,"Set3"), size=~WrittenFrequency,
        marker=list(opacity=0.8)) %>% 
  layout(showlegend = FALSE) %>% 
  animation_opts(frame = 800, transition = 795) %>% 
  config(displayModeBar = F) 

# Exercise: change frame and transition speed parameters to something different.
```


```{r datasaurus}
library(datasauRus) # Datasets where the summary statistics and correlation between x and y is almost identical, despite great differences in the data is distributed, which becomes apparent when visualized.

plot_ly(datasaurus_dozen, x=~x, y=~y, type = 'scatter', mode = 'markers', frame=~dataset) %>%
  layout(showlegend = FALSE) %>% animation_opts(frame = 1000, transition = 500) %>% 
  config(displayModeBar=F)


# Another example of using animation to explain a concept: this is from a recent conference talk of mine:
df=data.frame(d=c(runif(100,-1,1)+rnorm(100,0,0.5),sort(runif(100,-0.6,0.6))+rnorm(100,0,0.5), sort(runif(100,-1,1))+rnorm(100, 0, 0.1)), R2=as.factor(c(rep("0",100), rep("0.3",100), rep("0.95",100) )))
plot_ly(df, y=~d, x=rep(seq(-1,1,length.out = 100),3), color=~R2, colors=c("dimgray", "darkgreen", "darkred"), hoverinfo="none", frame = ~R2,type = 'scatter', mode = 'markers',showlegend = F) %>%
  layout(yaxis=list(title="")) %>% 
  animation_button(visible=FALSE)

```


# R marks the spot

Making maps programmatically based on data might come in handy if your worked with demographic data, or dialects, areal sociolinguistics, etc. We will look at two ways of plotting maps in R (there are numerous packages for that, all slightly different).

## Static maps

```{r}
library(raster)  # load the package to deal with map shapefiles and download maps

uk = getData("GADM", country = "United Kingdom", level = 2) # download UK map (needs the raster package to be loaded and internet connection)
par(mar=c(2,2,1,0), cex.axis=0.5, cex.main=0.8) # change plot area for better visibility - mar defines the margins, which are usually used for the axes and labels (reset using dev.off() later)
plot(uk, lwd=0.1) # plot the UK
points(-3.1833, 55.9533, pch=20, col="blue", cex=2) # hello :)

# Let's zoom into Scotland
scotland = uk[uk$NAME_1 == "Scotland",]  # subsets the map object
plot(scotland, lwd=0.2, xlim=c(-9,0), ylim=c(54,61), col=rev(colorRampPalette(c("white", "goldenrod4"))(15)), main="ScotSurvey Q49: how much do you love potatoes?")
axis(1); axis(2); grid(col=rgb(0,0,0,0.2))   # add grid and latitude/longitude axes

# Exercise: use the same subsetting method to plot only Wales. 
# If you get a blank plot: you probably copied the plot() call from above. The longitude and latitude constraints defined there will not work for Wales...
```

## Interactive maps

Here's a quick look into making interactive maps using the plotly package. If you need these sort of things in your work, also check out `leaflet`, which is good for working with very detailed (google-maps-scale) maps, and `ggmap`, an extension of ggplot2.
```{r, eval=T, echo=T}
# Let's do Europe.
eur = data.frame(country = c("AUT","BEL","BGR","HRV","CYP","CZE","DNK","EST","FIN","FRA","DEU","GRC","HUN","IRL","ITA","LVA","LTU","LUX","MLT","NLD","POL","PRT","ROU","SVK","SVN","ESP","SWE","GBR", "NOR", "ISL", "RUS", "UKR", "BLR"), value = sample(seq(0,5,0.1),33)) # create some data

# Note this uses plot_geo() instead of plot_ly(); it uses the world map by default, but we'll limit the scope. 
plot_geo(eur) %>% add_trace(locations = ~country, mode="none") %>% layout(geo = list(scope="europe")) # zoomable map

# Let's actually use it for something. 
# I'll just use the magrittr pipes here because they are handy.
plot_geo(eur) %>% 
  add_trace(z = ~value, locations = ~country, color = ~value, colors = c("darkred", "lightgreen")) %>%
  colorbar(title = "", thickness=10) %>% 
  layout(geo = list(scope="europe"), title="EurSoc Survey Q233: how manly is the Scottish kilt?", margin=list(l=0,r=0,b=0,t=30)) %>% 
  add_annotations(x= 1.04, y= 1, text = "very", showarrow = F) %>% add_annotations(x= 1.04, y= 0.52, text = "so about that..", showarrow = F)

```



# Let's make some slides

It's fairly straightforward to produce slides (websites, posters, books) in R using R Markdown, and export into html, pdf, or Word docx. We'll need to create a new file for this part.

Exercise. Click on the icon with the green plus on a white background in the top left corner, choose "R Markdown...", then "Presentation", and then "Slidy". Slidy is a basic, simple to use slide deck template (by the way, if you are willing to fiddle a bit with CSS, I'd recommend using the `xaringan` package instead).
Change the title to anything you want, and add author: your name into the YAML header on top.
Now copy this code block and use it to replace the short code block in the new file where it says "Slide with Plot".
Then click "Knit" (next to the little bar of yarn icon) on the top toolbar. RStdudio will ask you to save the new file, just save it anywhere.

```{r}

plot_ly(iris, # this uses a base dataset on some flower statistics
        x=~Petal.Width*2,
        y=~Petal.Length, 
        z=~Sepal.Length, 
        type="scatter3d", mode="markers",color=~Species, colors=brewer.pal(3,"Dark2"), marker=list(opacity=0.7)) %>% 
  layout( scene = list(xaxis=list(title="Petal width", showline=T),
                      yaxis=list(title="Petal length", showline=T), 
                      zaxis=list(title="Sepal length", showline=T))) %>%
  config(displayModeBar = F) 

```

An important note on data: when producing an html file from an R Markdown rmd file, functions and objects in the current global environment cannot be accessed. That means that if you're using a dataset from a package (like we've been doing), you'd need to load that package (i.e. include a `library(package)` call in a code block); if you're using your own data, you need to include code to import it. It often makes sense to deal with data processing in a separate script, save the results as an .RData file, and then just load the RData (using `load(file.RData)`) in the markdown file you intend to knit, instead of doing data cleaning and analysis upon every time you re-knit.

A couple of examples of things that I've myself used R Markdown for:

- my personal website: https://andreskarjus.github.io
- the cover page of the aRt of the figure workshops: https://andreskarjus.github.io/artofthefigure/
- this recent conference poster: https://andreskarjus.github.io/isle_poster
- a past seminar talk: https://andreskarjus.github.io/evoforces_cletalk/slides.html



# Final words on attributions, citing and references

Before we finish, a word on R and its packages. It's all free open-source software, meaning countless people have invested a lot of their own time into making this possible. If you use R, do cite it in your work (use the handy `citation()` command in R to get an up to date reference, both in plain text and BibTeX). To cite a package, use `citation("package name")`. You are also absolutely welcome to use any piece of code from this workshop, but in that case I would likewise appreciate a reference:

Karjus, Andres (2018). aRt of the Figure. GitHub repository, https://github.com/andreskarjus/artofthefigure. Bibtex:
```
@misc{karjus_artofthefigure_2018, author = {Karjus, Andres}, title = {aRt of the Figure}, year = {2018}, publisher = {GitHub}, journal = {GitHub repository}, howpublished = {\url{https://github.com/andreskarjus/artofthefigure}}, DOI = {10.5281/zenodo.1213335} } 
```


# Knitting time

That's it for today. Do play around with these things later when you have time, and look into the bonus sections for extras. If you get stuck, Google is your friend; also, check out www.stackoverflow.com - this site is a goldmine of programming (including R) questions and solutions.

Also, if you are looking for consulting on data analysis and visualization or more workshops, take a look at my website https://andreskarjus.github.io/ . I am available for booking via the Edinburgh Uni PPLS Writing Centre (this service is for PPLS students only though) and sometimes hold workshops on these topics. If you want to stay updated keep an eye on my Twitter @AndresKarjus.

---

But wait! There's one more thing to do. Since this too is an R Markdown document, we can "knit" it into a nice HTML (or PDF, or Word) report file - it will show both the code and the plots produced by the code. Note that unfortunately this will not work if you have errors in your code - marked by the little red x signs on the left side vertical bar. 
To knit, click the `Knit` button (with the little blue ball of yarn) above the script window. If the code is without errors, an HTML document will appear.


---

---

---

# Appendix. Getting your own data into R and getting plots out of R.

Once you get around to working with your own data, you'll need to import it into R to be able to make plots based on it. There are a number of ways of doing that; but also datasets and corpora come in different formats, so unfortunately there's no single magic solution to import everything, you usually need to figure out the format of the data beforehand. Below are some examples.

## Table (csv, Excel, txt) into R, import from file

This is probably the most common use case. If your data is in an Excel file formal (.xls, .xlsx), you are better off saving it as a plain text file (although there are packages to import directly from these formats, as well as from SPSS .sav files). The commands for that are read.table(), read.csv() and read.delim(). They basically all do the same thing, but differ in their default settings. For very large datasets or corpora, you might want to look into `data.table` instead.
```{r, eval=F, echo=T}
# an example use case with parameters explained
mydata = read.table(file="path/to/my/file.txt", # full file path as a string
                    header=T,      # if the first row contains column names
                    row.names=1,   # if the 1st (or other) column is row names
                    sep="\t",      # what character separates columns in the text file*
                    quote="",      # if there are " or ' marks in any columns, set this to ""
                    )
# * "\t" is for tab (default if you save a text file from Excel), "," for csv, " " if space-spearated, etc
# for more and to check the defaults, see help(read.table)
# the path can be just a file name, if the file is in the working (R's "default") directory; use getwd() to check where that is, and setwd(full/path/to/folder) to set it (or you can use RStudio's Files tab, click on More)
# If your file has an encoding other than Latin or UTF-8, specify that using the encoding parameter.

mydata = read.table(file.choose() )   # alternatively: this opens a window to browse for files; specify parameters as appropriate
```

## Importing from clipboard

There is a simple way to import data from the clipboard. While importing from files is generally a better idea (you can always re-run the code and it will find the data itself), sometimes this is handy, like quickly grabbing a little piece of table from Excel. It differs between OSes:
```{r, eval=F, echo=T}
mydata = read.table(file = "clipboard")       # in Windows (add parameters as necessary)
mydata = read.table(file = pipe("pbpaste"))   # on a Mac (add parameters as necessary)
```

## Importing text

For text, the `readLines()` command usually works well enough (its output is a character vector, so if the text file has 10 lines, then readLines produces a vector of length 10, where each line is an element in that vector (you could use strsplit() or quanteda's functions to further split it into words. If the text is organized neatly in columns (e.g., like the COHA corpus), however, you might still consider read.table(), but probably with the `stringsAsFactors=FALSE` parameter (this avoids making long text strings into factors; check out the help file if needed). 
A corpus may be encoded using XML - there is the `xml2` package (an improvement on the older `XML` package) for that, but watch out for memory leaks if importing and parsing multiple files (this is a know issue).

## Exporting plots

RStudio has handy options to export plots - click on `Export` on top of the plot panel, and choose the output format. Plots can be exported using R code as well - this is in fact a better approach, since otherwise you would have to click through the Export menus again every time you change your plot and need to re-export. Look into the help files of the `jpeg` and `pdf` functions to see how this works. Interactive plots can be either included in R Markdown based html files, or exported as separate html files (which you can then upload as such, integrate into a website, or plug it it using an iframe).

## Anything else

There are also packages to import and manipulate images, text, GIS map data, relational databases, data from all sorts of other file formats (like XML, HTML, Google Sheets), scrape websites, do OCR on scanned documents, and much more. Just google around a bit and you'll surely find what you need.

---
